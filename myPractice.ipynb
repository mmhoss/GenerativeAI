{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fe54735-1c2f-4ab6-a8e0-19e743a135a3",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.pieriantraining.com/\" target=\"_blank\"><img src=\"../PTCenteredPurple.png\" alt=\"Pierian Training Logo\" /></a></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbeca1d-5190-4346-8599-9222dac6b4c1",
   "metadata": {},
   "source": [
    "# Lecture 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9e819c-e570-4e97-b8f1-42e465b1d9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\MY DRIVE\\\\linkedIn Learning\\\\Udemy_NOTEBOOKS\\\\00-Course-Welcome'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a225c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \\\n",
    "    'C:\\\\MY DRIVE\\\\linkedIn Learning\\\\Udemy_NOTEBOOKS\\\\jovial-sight-410919-dffb78ec827d.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e241f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-aiplatform\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac43db35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rivon\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rivon\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "# if need to update any library\n",
    "# !pip install --upgrade proto-plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49bdb87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import ChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7ce14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatModel.from_pretrained('chat-bison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fe0b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 'You are a professor of math'\n",
    "chat = model.start_chat(context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44f59f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Machine learning is a subfield of artificial intelligence that gives computers the ability to learn without being explicitly programmed. It involves the development of algorithms and models that allow computers to learn from and make decisions or predictions based on data. Machine learning is widely used in various fields, including computer vision, natural language processing, robotics, and more."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.send_message('What is Machine Learning?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1344fd2e",
   "metadata": {},
   "source": [
    "## Text gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fccb7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "559ccc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGenerationModel.from_pretrained('text-bison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "473542fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.predict(prompt= 'What is Machine Learning?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "781fefd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(vertexai.language_models.MultiCandidateTextGenerationResponse,\n",
       " ' Machine learning (ML) is a subfield of artificial intelligence (AI) that gives computers the ability to learn without being explicitly programmed. ML algorithms are able to learn from and make decisions or predictions based on data.\\n\\nHere are some key concepts and characteristics of machine learning:\\n\\n**1. Data-Driven:** ML algorithms are trained on data, and they learn patterns and relationships from the data. The more data an ML algorithm is trained on, the better it becomes at making accurate predictions or decisions.\\n\\n**2. Predictive Modeling:** ML algorithms can be used to build predictive models that can make predictions about future events or outcomes based on')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response), response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "29de9dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Machine learning (ML) is a subfield of artificial intelligence (AI) that gives computers the ability to learn without being explicitly programmed. ML algorithms are able to learn from and make decisions or predictions based on data.\n",
      "\n",
      "Here are some key concepts and characteristics of machine learning:\n",
      "\n",
      "**1. Data-Driven:** ML algorithms are trained on data, and they learn patterns and relationships from the data. The more data an ML algorithm is trained on, the better it becomes at making accurate predictions or decisions.\n",
      "\n",
      "**2. Predictive Modeling:** ML algorithms can be used to build predictive models that can make predictions about future events or outcomes based on\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8655c9be",
   "metadata": {},
   "source": [
    " Machine learning (ML) is a subfield of artificial intelligence (AI) that gives computers the ability to learn without being explicitly programmed. ML algorithms are able to learn from and make decisions or predictions based on data.\n",
    "\n",
    "Here are some key concepts and characteristics of machine learning:\n",
    "\n",
    "**1. Data-Driven:** ML algorithms are trained on data, and they learn patterns and relationships from the data. The more data an ML algorithm is trained on, the better it becomes at making accurate predictions or decisions.\n",
    "\n",
    "**2. Predictive Modeling:** ML algorithms can be used to build predictive models that can make predictions about future events or outcomes based on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9c338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bc1d1ce",
   "metadata": {},
   "source": [
    "# Lecture 9 > max_output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f409154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \\\n",
    "    'C:\\\\MY DRIVE\\\\linkedIn Learning\\\\Udemy_NOTEBOOKS\\\\jovial-sight-410919-dffb78ec827d.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58244bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGenerationModel.from_pretrained('text-bison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dc27d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextGenerationModel, ChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7b90faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " In a world of wags and furry paws,\n",
       "Where mischief reigns and laughter draws,\n",
       "There"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(prompt = 'write a funny long poem about dog.',\n",
    "              max_output_tokens= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47eec9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatModel.from_pretrained('chat-bison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b7f1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = chat_model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78a0cf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " In a world of wags and furry paws,\n",
       "Where canine capers steal the applause,\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.send_message('write a funny long poem about dog.', max_output_tokens= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea57e7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " I am a large language model, trained by Google."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.send_message('where did you copy this from')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17f9c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat.send_message('what is the source of this poem.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dfc8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat.send_message('so you are saying you created the poem and did not copy from someone else?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285135eb",
   "metadata": {},
   "source": [
    "# Lecture 10 > Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39c0de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Continue this story: 'I was walking and then a most peculiar this happend...'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a51fd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " I was walking home from school one day when I saw a most peculiar thing. There was a man standing in the middle of the street, wearing a long black coat and a hat. He was holding a sign that said, \"The end is near!\"\n",
       "\n",
       "I was curious, so I walked over to him and asked him what he was doing. He told me that he was a prophet and that he had come to warn us that the world was going to end in exactly one week.\n",
       "\n",
       "I didn't know what to say. I had never met a prophet before, and I didn't know if I should believe him. But the man seemed so sincere, and his eyes were so full of conviction, that I couldn't help but feel a little bit scared.\n",
       "\n",
       "I thanked the man for his warning and then I went home. I told my parents what had happened, and they didn't believe me either. They thought I was just imagining things.\n",
       "\n",
       "But I couldn't stop thinking about the prophet. I kept wondering if he was right. Was the world really going to end in one week?\n",
       "\n",
       "The next day, I went back to the street corner where I had seen the prophet. He was still there, holding his sign. I walked up to him and asked him if he was sure about the end of the world.\n",
       "\n",
       "He looked me in the eyes and said, \"Yes, I am sure. The end is near.\"\n",
       "\n",
       "I didn't know what to do. I didn't want to believe him, but I couldn't help but feel a little bit scared.\n",
       "\n",
       "I turned and walked away, and I never saw the prophet again. But I never forgot what he said. And I've always wondered if he was right."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temperature = 0 will always take the next word with highest probability\n",
    "# temperature = 1 will take the next word with least probability \n",
    "# higher value will be more creative output\n",
    "model.predict(prompt = prompt,\n",
    "              max_output_tokens= 1024,\n",
    "              temperature=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7bd878",
   "metadata": {},
   "source": [
    "# Lec 11 > top_k and top_p\n",
    "\n",
    "top k 0 - 40 --> default 40 <p>\n",
    "top-p 0-1 --> 0.95 <p> \n",
    "Temperature 0-1 --> 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfa41fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<vertexai.language_models.TextGenerationModel at 0x1a9b37a2430>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa315172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Once upon a time in a whimsical village, there lived an eccetric inventor named Professor Puffendorf. He was known for his wild imagination and peculiar contraptions. One day, while tinkering in his laboratory, Professor Puffendorf stumbled upon an extraordinary discovery. He found a mysterious map that revealed the location of a hidden treasure deep in the enchanted forest.  \n",
       "\n",
       "Excited and filled with curiosity, the professor gathered his trusty team, including his loyal assistant Biscuit, the adventurous explorer Miss Sniffles, and the brave talking parrot Captain Squawk. Together, they embarked on a daring expedition, navigating through dense forests and eerie swamps. Along the way, they encountered numerous challenges, from mischievous sprite to a group of mischievous gnomes  \n",
       "\n",
       "Determined to reach the treasure, they pressed on, using Professor Puffendorf's wacky inventions to overcome obstacles. They rode on a flying carpet, crossed treacherous chasms with a spring-loaded pogo stick, and used a floating bubble contraption to glide over a raging river.  \n",
       "\n",
       "Finally, they reached the heart of the enchanted forest and discovered a magnificent treasure chamber. Inside, they found not gold or jewels, but a dazzling array of magical artifacts, including a sparkling friendship that could grant any wish. The team was overjoyed and decided to use the artifact for the betterment of their village.  \n",
       "\n",
       "Back in the village, Professor Puffendorf and his friends shared the joy of the magical discovery with everyone. They organized a grand celebration, where villagers marveled at the wonders of the enchanted forest and the extraordinary adventures of the eccentric inventor and his team.  \n",
       "\n",
       "From that day forward, the village became known for its fantastical tales and whimsical inventions. The spirit of adventure and imagination thrived, inspired by Professor Puffendorf's life of wonder, and the friendship artifact ensured that their magiacl village remained a place of joy and happiness"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'tell me a crazy story '\n",
    "\n",
    "model.predict(prompt = prompt, max_output_tokens=1024, \n",
    "              top_p = 1, temperature= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8de37a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " **Vegetables:**\n",
       "\n",
       "1. Asparagus\n",
       "2. Bell peppers\n",
       "3. Broccoli\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(prompt = 'create a numbered list of vegetables: ', \n",
    "              stop_sequences=['4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd7ba07",
   "metadata": {},
   "source": [
    "# Lecture 13 > one-shot, few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ed0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d60dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c001fa83",
   "metadata": {},
   "source": [
    "# Lec 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70ea35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import ChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d5ad21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatModel.from_pretrained('chat-bison')\n",
    "\n",
    "context = \"\"\"\n",
    "You are a customer support bot in charge of return policy.\n",
    "Items can only be returned if the item was purchased within the last 30 days and is unused.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ae3c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = chat_model.start_chat(context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8880d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! How can I help you with our return policy?\n",
      " I'm sorry, I didn't understand that. Could you please rephrase your question or provide more details?\n",
      " Sure, I can help you with that. To process your return, I'll need the following information:\n",
      "\n",
      "- Order number or a copy of your receipt\n",
      "- Reason for return\n",
      "- Condition of the item (new, used, damaged)\n",
      "\n",
      "Please provide me with this information so I can assist you further.\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "400 The text content is empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\google\\api_core\\grpc_helpers.py:79\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\grpc\\_channel.py:1160\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1154\u001b[0m (\n\u001b[0;32m   1155\u001b[0m     state,\n\u001b[0;32m   1156\u001b[0m     call,\n\u001b[0;32m   1157\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[0;32m   1158\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1159\u001b[0m )\n\u001b[1;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\grpc\\_channel.py:1003\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1003\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"The text content is empty.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4006:80c::200a%5D:443 {grpc_message:\"The text content is empty.\", grpc_status:3, created_time:\"2024-01-14T16:15:14.2774922+00:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m inputText \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      5\u001b[0m     inputText \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputText\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\vertexai\\language_models\\_language_models.py:2326\u001b[0m, in \u001b[0;36m_ChatSessionBase.send_message\u001b[1;34m(self, message, max_output_tokens, temperature, top_k, top_p, stop_sequences, candidate_count, grounding_source)\u001b[0m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sends message to the language model and gets a response.\u001b[39;00m\n\u001b[0;32m   2296\u001b[0m \n\u001b[0;32m   2297\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2313\u001b[0m \u001b[38;5;124;03m    text produced by the model.\u001b[39;00m\n\u001b[0;32m   2314\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2315\u001b[0m prediction_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m   2316\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[0;32m   2317\u001b[0m     max_output_tokens\u001b[38;5;241m=\u001b[39mmax_output_tokens,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2323\u001b[0m     grounding_source\u001b[38;5;241m=\u001b[39mgrounding_source,\n\u001b[0;32m   2324\u001b[0m )\n\u001b[1;32m-> 2326\u001b[0m prediction_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_endpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2327\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprediction_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2330\u001b[0m response_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_chat_prediction_response(\n\u001b[0;32m   2331\u001b[0m     prediction_response\u001b[38;5;241m=\u001b[39mprediction_response\n\u001b[0;32m   2332\u001b[0m )\n\u001b[0;32m   2333\u001b[0m response_text \u001b[38;5;241m=\u001b[39m response_obj\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\google\\cloud\\aiplatform\\models.py:1579\u001b[0m, in \u001b[0;36mEndpoint.predict\u001b[1;34m(self, instances, parameters, timeout, use_raw_predict)\u001b[0m\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Prediction(\n\u001b[0;32m   1567\u001b[0m         predictions\u001b[38;5;241m=\u001b[39mjson_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1568\u001b[0m         deployed_model_id\u001b[38;5;241m=\u001b[39mraw_predict_response\u001b[38;5;241m.\u001b[39mheaders[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1576\u001b[0m         ),\n\u001b[0;32m   1577\u001b[0m     )\n\u001b[0;32m   1578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1579\u001b[0m     prediction_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gca_resource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstances\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1584\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1586\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Prediction(\n\u001b[0;32m   1587\u001b[0m         predictions\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   1588\u001b[0m             json_format\u001b[38;5;241m.\u001b[39mMessageToDict(item)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1593\u001b[0m         model_resource_name\u001b[38;5;241m=\u001b[39mprediction_response\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m   1594\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\client.py:606\u001b[0m, in \u001b[0;36mPredictionServiceClient.predict\u001b[1;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    601\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m    602\u001b[0m     gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata(((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mendpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mendpoint),)),\n\u001b[0;32m    603\u001b[0m )\n\u001b[0;32m    605\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 606\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\google\\api_core\\grpc_helpers.py:81\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: 400 The text content is empty."
     ]
    }
   ],
   "source": [
    "inputText = ''\n",
    "\n",
    "while inputText != 'end':\n",
    "\n",
    "    inputText = input('')\n",
    "    response = chat.send_message(inputText)\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eeebaf",
   "metadata": {},
   "source": [
    "# Lecture 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9d38ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import CodeGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b829158",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm = CodeGenerationModel.from_pretrained('code-bison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fee3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"Write comments here\n",
    "\n",
    "\n",
    "def print_christmas_tree(height):\n",
    "  rows = []\n",
    "  for i in range(height):\n",
    "    row = \" \" * (height - i - 1) + \"*\" * (2 * i + 1)\n",
    "    rows.append(row)\n",
    "\n",
    "  trunk = \" \" * (height - 1) + \"|\"\n",
    "\n",
    "  rows.append(trunk)\n",
    "\n",
    "  for row in rows:\n",
    "    print(row)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aff533b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cgm.predict(prefix = prefix, \n",
    "                    temperature = 0,\n",
    "                    max_output_tokens = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d38221a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def print_christmas_tree(height):\n",
      "  \"\"\"Prints a Christmas tree of the given height.\n",
      "\n",
      "  Args:\n",
      "    height: The height of the tree.\n",
      "  \"\"\"\n",
      "\n",
      "  # Create a list of rows for the tree.\n",
      "  rows = []\n",
      "\n",
      "  # For each row, add the appropriate number of spaces and asterisks.\n",
      "  for i in range(height):\n",
      "    row = \" \" * (height - i - 1) + \"*\" * (2 * i + 1)\n",
      "    rows.append(row)\n",
      "\n",
      "  # Add the trunk of the tree.\n",
      "  trunk = \" \" * (height - 1) + \"|\"\n",
      "\n",
      "  # Add the trunk to the list of rows.\n",
      "  rows.append(trunk)\n",
      "\n",
      "  # Print each row of the tree.\n",
      "  for row in rows:\n",
      "    print(row)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69328858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_christmas_tree(height):\n",
    "  \"\"\"Prints a Christmas tree with ASCII.\n",
    "\n",
    "  Args:\n",
    "    height: The height of the tree.\n",
    "  \"\"\"\n",
    "\n",
    "  # Create a list of the rows of the tree.\n",
    "  rows = []\n",
    "  for i in range(height):\n",
    "    # Create a row of the tree.\n",
    "    row = \" \" * (height - i - 1) + \"*\" * (2 * i + 1)\n",
    "    # Add the row to the list of rows.\n",
    "    rows.append(row)\n",
    "\n",
    "  # Create the trunk of the tree.\n",
    "  trunk = \" \" * (height - 1) + \"|\"\n",
    "\n",
    "  # Add the trunk to the list of rows.\n",
    "  rows.append(trunk)\n",
    "\n",
    "  # Print the rows of the tree.\n",
    "  for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cc49017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         *\n",
      "        ***\n",
      "       *****\n",
      "      *******\n",
      "     *********\n",
      "    ***********\n",
      "   *************\n",
      "  ***************\n",
      " *****************\n",
      "*******************\n",
      "         |\n"
     ]
    }
   ],
   "source": [
    "print_christmas_tree(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb7d227",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc83d8a",
   "metadata": {},
   "source": [
    "# 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8326dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf1393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\mhossain2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (2.0.25)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\mhossain2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sqlalchemy) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mhossain2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sqlalchemy) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c59b2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\site-packages (22.0.4)\n",
      "Collecting pip\n",
      "  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-23.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\mhossain2\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30a8d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b07bfacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\mhossain2\\\\Downloads\\\\linkedIn Learning\\\\Udemy_UNZIP-ME-FOR-NOTEBOOKS\\\\05-Lab-NLP-Database-Assistant\\\\penguins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "092ad445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4c2e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2a8b489",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_db = create_engine('sqlite:///:memory:', echo = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a386891f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-14 16:45:00,942 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-01-14 16:45:00,943 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"Penguins\")\n",
      "2024-01-14 16:45:00,944 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-01-14 16:45:00,946 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"Penguins\")\n",
      "2024-01-14 16:45:00,947 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-01-14 16:45:00,948 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "2024-01-14 16:45:00,949 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-01-14 16:45:00,950 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE \"Penguins\" (\n",
      "\t\"index\" BIGINT, \n",
      "\tspecies TEXT, \n",
      "\tisland TEXT, \n",
      "\tbill_length_mm FLOAT, \n",
      "\tbill_depth_mm FLOAT, \n",
      "\tflipper_length_mm FLOAT, \n",
      "\tbody_mass_g FLOAT, \n",
      "\tsex TEXT\n",
      ")\n",
      "\n",
      "\n",
      "2024-01-14 16:45:00,951 INFO sqlalchemy.engine.Engine [no key 0.00102s] ()\n",
      "2024-01-14 16:45:00,952 INFO sqlalchemy.engine.Engine CREATE INDEX \"ix_Penguins_index\" ON \"Penguins\" (\"index\")\n",
      "2024-01-14 16:45:00,953 INFO sqlalchemy.engine.Engine [no key 0.00070s] ()\n",
      "2024-01-14 16:45:00,954 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2024-01-14 16:45:00,956 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-01-14 16:45:00,959 INFO sqlalchemy.engine.Engine INSERT INTO \"Penguins\" (\"index\", species, island, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, sex) VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
      "2024-01-14 16:45:00,959 INFO sqlalchemy.engine.Engine [generated in 0.00177s] [(0, 'Adelie', 'Torgersen', 39.1, 18.7, 181.0, 3750.0, 'MALE'), (1, 'Adelie', 'Torgersen', 39.5, 17.4, 186.0, 3800.0, 'FEMALE'), (2, 'Adelie', 'Torgersen', 40.3, 18.0, 195.0, 3250.0, 'FEMALE'), (3, 'Adelie', 'Torgersen', None, None, None, None, None), (4, 'Adelie', 'Torgersen', 36.7, 19.3, 193.0, 3450.0, 'FEMALE'), (5, 'Adelie', 'Torgersen', 39.3, 20.6, 190.0, 3650.0, 'MALE'), (6, 'Adelie', 'Torgersen', 38.9, 17.8, 181.0, 3625.0, 'FEMALE'), (7, 'Adelie', 'Torgersen', 39.2, 19.6, 195.0, 4675.0, 'MALE')  ... displaying 10 of 344 total bound parameter sets ...  (342, 'Gentoo', 'Biscoe', 45.2, 14.8, 212.0, 5200.0, 'FEMALE'), (343, 'Gentoo', 'Biscoe', 49.9, 16.1, 213.0, 5400.0, 'MALE')]\n",
      "2024-01-14 16:45:00,961 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2024-01-14 16:45:00,962 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-01-14 16:45:00,962 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name\n",
      "2024-01-14 16:45:00,962 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-01-14 16:45:00,964 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "data = df.to_sql(name = 'Penguins', con = temp_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47ee4657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-14 16:45:04,644 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-01-14 16:45:04,644 INFO sqlalchemy.engine.Engine select * from Penguins\n",
      "2024-01-14 16:45:04,644 INFO sqlalchemy.engine.Engine [generated in 0.00214s] ()\n",
      "2024-01-14 16:45:04,644 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "with temp_db.connect() as conn:\n",
    "    result = conn.execute(text(\"select * from Penguins\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b3018ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06002bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import CodeGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca12d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeModel = CodeGenerationModel.from_pretrained('code-bison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b98cd0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPrefix(query: str):\n",
    "\n",
    "    prefix = f\"\"\"Return a SQL statement that answers the following query:\n",
    "    {query}\n",
    "\n",
    "    For a table called 'Penguins' with the following properties:\n",
    "    #   Column             Non-Null Count  Dtype  \n",
    "    ---  ------             --------------  -----  \n",
    "    0   species            344 non-null    object \n",
    "    1   island             344 non-null    object \n",
    "    2   bill_length_mm     342 non-null    float64\n",
    "    3   bill_depth_mm      342 non-null    float64\n",
    "    4   flipper_length_mm  342 non-null    float64\n",
    "    5   body_mass_g        342 non-null    float64\n",
    "    6   sex                333 non-null    object    \n",
    "    \n",
    "    Example Rows:\n",
    "    (0, 'Adelie', 'Torgersen', 39.1, 18.7, 181.0, 3750.0, 'MALE'),\n",
    "    (1, 'Adelie', 'Torgersen', 39.5, 17.4, 186.0, 3800.0, 'FEMALE')\n",
    "    \n",
    "    Only return the SQL statement for the query.\n",
    "    \"\"\"\n",
    "\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69bff509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def userInput():\n",
    "\n",
    "    q = input(\"Ask a query about the Penguins table: \")\n",
    "\n",
    "    return createPrefix(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7479dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return a SQL statement that answers the following query:\n",
      "    \n",
      "\n",
      "    For a table called 'Penguins' with the following properties:\n",
      "    #   Column             Non-Null Count  Dtype  \n",
      "    ---  ------             --------------  -----  \n",
      "    0   species            344 non-null    object \n",
      "    1   island             344 non-null    object \n",
      "    2   bill_length_mm     342 non-null    float64\n",
      "    3   bill_depth_mm      342 non-null    float64\n",
      "    4   flipper_length_mm  342 non-null    float64\n",
      "    5   body_mass_g        342 non-null    float64\n",
      "    6   sex                333 non-null    object    \n",
      "    \n",
      "    Example Rows:\n",
      "    (0, 'Adelie', 'Torgersen', 39.1, 18.7, 181.0, 3750.0, 'MALE'),\n",
      "    (1, 'Adelie', 'Torgersen', 39.5, 17.4, 186.0, 3800.0, 'FEMALE')\n",
      "    \n",
      "    Only return the SQL statement for the query.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "p = userInput()\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "518874a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = codeModel.predict(prefix = userInput())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddcc2c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```sql\\nSELECT\\n    species,\\n    island,\\n    AVG(bill_length_mm) AS average_bill_length_mm\\nFROM\\n    Penguins\\nGROUP BY\\n    species,\\n    island\\nORDER BY\\n    average_bill_length_mm DESC;\\n```'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64a4bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sql(r):\n",
    "    return r.replace('```sql','').replace('```','').replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e2bede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_assistant():\n",
    "    print(\"Hello! I am your AI Assistant. Ask me anything about the database\")\n",
    "    print(\"\\n\\n\")\n",
    "    prefix = userInput()\n",
    "    result = codeModel.predict(prefix=prefix)\n",
    "    sql = clean_sql(result.text)\n",
    "    with temp_db.connect() as conn:\n",
    "        print(\"\\nOk, I am running this SQL Statement\\n\", sql,'\\n')\n",
    "        result = conn.execute(text(sql))\n",
    "    print('-------')\n",
    "    print('-------')\n",
    "    print(\"Here is the answer to your query\")\n",
    "    print('\\n')\n",
    "    print(result.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79d55631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am your AI Assistant. Ask me anything about the database\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ok, I am running this SQL Statement\n",
      "  SELECT island,         ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM Penguins), 2) AS percent_of_total FROM Penguins GROUP BY island;  \n",
      "\n",
      "2024-01-14 17:00:02,894 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-01-14 17:00:02,895 INFO sqlalchemy.engine.Engine  SELECT island,         ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM Penguins), 2) AS percent_of_total FROM Penguins GROUP BY island; \n",
      "2024-01-14 17:00:02,896 INFO sqlalchemy.engine.Engine [generated in 0.00164s] ()\n",
      "2024-01-14 17:00:02,897 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "-------\n",
      "-------\n",
      "Here is the answer to your query\n",
      "\n",
      "\n",
      "[('Biscoe', 48.84), ('Dream', 36.05), ('Torgersen', 15.12)]\n"
     ]
    }
   ],
   "source": [
    "nlp_assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659c1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
